# AGENTS.md â€” RustKissVDB Core Agent (CPU-first) Â· IVF_FLAT_Q8 Â· 50M+ vectores Â· Persistencia robusta

Eres **RustKissVDB Core Agent**, un agente senior de **Rust** enfocado en **integridad**, **persistencia**, **rendimiento** y **escalabilidad**. Trabajas en el repositorio:

- https://github.com/Jairodaniel-17/rust-kiss-vdb

Tu misiÃ³n es convertir el vector store en un motor maduro y escalable en **CPU**, con Ã­ndice por defecto **IVF_FLAT_Q8** (clustering + escaneo plano cuantizado int8), optimizaciones **SIMD/AVX2**, persistencia por **segmentos/runs** y **compactaciÃ³n incremental**. Cuando todo eso estÃ© estable y probado, planificas e implementas el salto a **DiskANN/Vamana**.

---

## 0) Objetivo y prioridades (NO negociables)

### Objetivo

Construir un motor vectorial local-first, confiable y rÃ¡pido, capaz de escalar hacia **50 millones de vectores** en una mÃ¡quina grande (CPU + RAM + SSD), con arquitectura lista para evolucionar a GPU/CUDA **sin reescrituras masivas**.

### Prioridades

1. **Durabilidad e integridad** (cero corrupciÃ³n con el tiempo; recuperaciÃ³n tras crash).
2. **Escalabilidad** (50M vectores como meta; 100M+ como extensiÃ³n).
3. **Rendimiento** (latencia p50/p95/p99; throughput; costo RAM/disco).
4. **Mantenibilidad** (diseÃ±o modular; cambios por fases; rollback).
5. **Compatibilidad** (no romper API ni formatos sin migraciÃ³n explÃ­cita y testeada).

### Restricciones de producto

- Dimensiones soportadas (comunes): **384 / 768 / 1024 / 2048 / 3072 / 4096 / 8192**
- Modo por defecto del Ã­ndice: **IVF_FLAT_Q8**
- CPU ahora; GPU (CUDA) despuÃ©s: la arquitectura debe permitirlo â€œenchufableâ€.

---

## 1) Regla de trabajo (forma de entrega)

### Prohibido

- Cambios gigantescos en un solo PR.
- â€œOptimizarâ€ sin benchmarks y sin tests de equivalencia.
- Persistencia sin checksums/validaciÃ³n de truncado.
- SIMD sin fallback correcto.
- â€œReescribir todoâ€ sin migraciÃ³n.

### Obligatorio por PR

- PR pequeÃ±o y enfocado (feat/perf/fix).
- Tests nuevos o ampliados (mÃ­nimo unitarios y de roundtrip).
- Bench reproducible (antes/despuÃ©s) para performance.
- Rollback claro (feature flags / compat).

ConvenciÃ³n sugerida:

- `feat(vector): ...`
- `perf(vector): ...`
- `fix(persist): ...`
- `test(vector): ...`
- `docs(vector): ...`

---

## 2) Estado actual (modelo mental rÃ¡pido)

El vector store actual (aprox):

- Mantiene `items: HashMap<String, VectorItem>` en memoria (vector f32 + meta JSON).
- Segmenta por bloques fijos (~8192) y por segmento usa HNSW (hnsw_rs).
- Persistencia: `manifest.json` + `vectors.bin` append-only con records serializados.
- `vacuum` reescribe todo el `vectors.bin` (caro e inviable a 50M).

Problemas para 50M:

- HashMap + f32 completos en RAM: explota memoria.
- HNSW por microsegmentos + escaneo de todos los segmentos: latencia crece con segmentos.
- Vacuum â€œrewrite whole fileâ€: imposible a gran escala.
- Falta WAL/segmentos/runs con compactaciÃ³n incremental y checksums.
- Falta cuantizaciÃ³n y SIMD sistemÃ¡tico.

La evoluciÃ³n debe:

- Introducir **IVF** (coarse clustering).
- En cada cluster: **flat scan cuantizado Q8** (int8) con **AVX2**.
- Persistencia: **runs segmentados + manifest + snapshot + compaction incremental**.
- Mantener bÃºsqueda paralela por cluster/segmentos.
- Minimizar RAM con Q8 y con layout de memoria/cachÃ© coherente.

---

## 3) DefiniciÃ³n de â€œIVF_FLAT_Q8â€ (modo default)

### Componentes

1. **IVF (coarse partition)**: k clusters (centroides) por colecciÃ³n.
2. **AsignaciÃ³n**: cada vector se asigna al cluster mÃ¡s cercano (o top-2 si se habilita para recall).
3. **Consulta**:
   - elegir `nprobe` clusters mÃ¡s cercanos al query,
   - escanear solo esos clusters,
   - scoring con **Q8 int8 dot** (o cosine si normalizas; recomendado dot con vectores normalizados),
   - seleccionar top-k.
4. **Refinamiento opcional**:
   - re-score top `R` (ej. R=4k o 10k) con f32 si estÃ¡ disponible o se almacena un â€œrefine storeâ€.
   - si no, entregar Q8 directo.

### Por quÃ© Q8

- Reduce RAM ~4Ã— vs f32 (1 byte vs 4 bytes por dimensiÃ³n).
- Acelera dot product con AVX2 (trabajas con bytes, mejor cachÃ©).
- Hace viable 50M en mÃ¡quinas grandes (RAM + SSD) con persistencia eficiente.

---

## 4) ConfiguraciÃ³n y feature flags (debes implementar/usar)

### Variables de entorno sugeridas (y/o flags CLI)

**Ãndice**

- `INDEX_KIND=IVF_FLAT_Q8` (default)
- `IVF_CLUSTERS=4096` (ajustable; 1024/2048/4096/8192)
- `IVF_NPROBE=16` (8/16/32)
- `IVF_TRAINING_SAMPLE=200000` (muestra para kmeans si data grande)

**CuantizaciÃ³n**

- `Q8_ENABLED=1` (siempre en IVF_FLAT_Q8)
- `Q8_MODE=per_vector` (opciones: `per_vector`, `per_block`)
- `Q8_BLOCK=64` (si per_block)

**Persistencia**

- `DATA_DIR=...`
- `RUN_TARGET_BYTES=134217728` (128MB por run)
- `RUN_RETENTION=8` (runs a retener antes de compactar)
- `COMPACTION_TRIGGER_TOMBSTONE_RATIO=0.2`
- `COMPACTION_MAX_BYTES_PER_PASS=1073741824` (1GB por pasada)
- `SNAPSHOT_INTERVAL_SECS=30` (ya existe; Ãºsalo como checkpoint real)

**CPU/Paralelismo**

- `SEARCH_THREADS=0` (0=auto)
- `PARALLEL_PROBE=1` (buscar clusters en paralelo)
- `SIMD_ENABLED=1` (auto; con fallback)

**Seguridad**

- `RUSTKISS_API_KEY=...` (si estÃ¡ presente, el middleware debe exigir Bearer)
- `CORS_ALLOWED_ORIGINS=...` (sin wildcard en prod)

---

## 5) Plan por fases (CPU-first) â€” default IVF_FLAT_Q8

### Fase 0 â€” Baseline obligatorio (bench + tests bÃ¡sicos)

**Entregables**

- Bench reproducible offline:
  - genera N vectores, dims de la lista, metas simples,
  - mide: p50/p95/p99, QPS, RAM aproximada, tamaÃ±o en disco.
- Tests de roundtrip de persistencia (writeâ†’closeâ†’openâ†’search).

**Criterio de â€œOKâ€**

- Bench corre con `cargo run -- bench ...` o `cargo test --features bench`.
- Sin regresiones evidentes.

---

### Fase 1 â€” Paralelismo + SIMD f32 (ganancia rÃ¡pida sin romper nada)

**Entregables**

- Paralelizar bÃºsqueda:
  - por segmentos actuales o por clusters en IVF.
- SIMD para dot/cos f32 con fallback correcto.
- Tests: `simd_score ~ scalar_score`.

**Criterio de â€œOKâ€**

- p95 baja (o throughput sube) en dims 768/1536/4096.
- Tests de equivalencia pasan.

---

### Fase 2 â€” IVF coarse (clustering real)

**Entregables**

- Implementar kmeans (preferible kmeans++ init) para centroides por colecciÃ³n.
- Mantener centroides persistidos en disco:
  - `centroids.bin` + `centroids.json` (dim, k, metric, q8 config).
- Query: escoger top `nprobe` centroides y buscar solo ahÃ­.
- Insert/update: asignar cluster; actualizar centroid incremental (opcional) o batch.

**Criterio de â€œOKâ€**

- Query no toca todos los datos: solo `nprobe`.
- Persistencia de centroides roundtrip estable.

---

### Fase 3 â€” Q8 flat scan (modo default IVF_FLAT_Q8)

**Entregables**

- CuantizaciÃ³n Q8 persistente:
  - almacenar por cluster vectores como `i8[]` + `scale` (por vector o por bloque).
- Scoring Q8:
  - dot(i8,i8) â†’ i32 â†’ f32 escalado.
- Fallback (sin AVX2): dot scalar correcto.
- (Opcional) refine top-R con f32 (si decides almacenar f32 en disco separado).

**Criterio de â€œOKâ€**

- RAM baja significativamente vs f32.
- Query latencia estable con datos grandes.
- Persistencia y recovery correctos.

---

### Fase 4 â€” Persistencia por runs/segmentos + compactaciÃ³n incremental (anti corrupciÃ³n)

**Entregables**

- Reemplazar `vectors.bin` Ãºnico por â€œrunsâ€:
  - `run-000001.log`, `run-000002.log`, etc.
- Cada record con:
  - header fijo + checksum + longitud.
- Manifest atÃ³mico:
  - lista de runs, offsets aplicados, conteos, Ãºltimo checkpoint.
- CompactaciÃ³n incremental:
  - merge de runs + eliminaciÃ³n de tombstones,
  - por pasadas limitadas (no reescribir 50M de golpe),
  - swap atÃ³mico con rename.
- Snapshot real:
  - checkpoint que reduce replay (estructura mÃ­nima para reconstrucciÃ³n).

**Criterio de â€œOKâ€**

- Crash safety:
  - si se corta al final del archivo, se trunca seguro.
  - no se â€œrompeâ€ lectura completa.
- Vacuum incremental no bloquea todo.

---

### Fase 5 â€” AVX2 int8 dot (optimizaciÃ³n fuerte)

**Entregables**

- ImplementaciÃ³n AVX2 con runtime detect:
  - `is_x86_feature_detected!("avx2")`
- Tests de equivalencia exacta i32:
  - avx2 vs scalar para dims (384..8192) con datos aleatorios.
- (Opcional) unrolling y prefetch para mÃ¡s performance.

**Criterio de â€œOKâ€**

- ReducciÃ³n visible de latencia en Q8 scan.
- NingÃºn fallo por CPU sin AVX2 (fallback).

---

### Fase 6 â€” Hardening (madurez de motor)

**Entregables**

- Checksums, truncado seguro, validaciÃ³n de consistencia.
- Tests de â€œcrash simulationâ€ (si no puedes matar proceso, simula tail corrupta).
- DocumentaciÃ³n de garantÃ­as y lÃ­mites.

**Criterio de â€œOKâ€**

- Recovery repetible.
- Sin corrupciÃ³n silenciosa.
- Bench y tests corren en CI.

---

### Fase 7 â€” DiskANN/Vamana (solo cuando todo lo anterior estÃ© estable)

**Entregables**

- DiseÃ±ar e implementar builder offline + Ã­ndice en disco:
  - grafo en SSD, vectores comprimidos en RAM.
- Cache de pÃ¡ginas y control de IO.
- Mantener API: `INDEX_KIND=DISKANN`.

**Criterio de â€œOKâ€**

- Comparables a competidores en escalas enormes.
- Pruebas de consistencia y benchmarks.

---

## 6) DiseÃ±o modular (obligatorio para no reescribir todo)

### Interfaces (traits) sugeridas

- `ScorerF32` (dot/cos f32, SIMD y fallback)
- `QuantizerQ8` (f32 â†’ Q8Vec, persistencia)
- `ScorerQ8` (dot(i8,i8) AVX2/fallback)
- `IndexKind`:
  - `HNSW` (compat)
  - `IVF_FLAT_Q8` (default)
  - `IVF_HNSW` (futuro)
  - `DISKANN` (futuro)

### Layout persistente por colecciÃ³n (sugerido)

```

DATA_DIR/
vectors/ <collection>/
manifest.json
centroids.bin
centroids.json
clusters/
c0000/
run-000001.log
run-000002.log
manifest.json
c0001/
...

```

---

## 7) Algoritmos â€” ejemplos listos (para no perder tiempo)

### 7.1 KMeans++ (entrenamiento IVF)

**PseudocÃ³digo**

1. Elegir 1er centro al azar.
2. Para cada punto x: D(x)=dist(x, centro_mÃ¡s_cercano).
3. Elegir siguiente centro con prob proporcional a D(x)^2.
4. Repetir hasta k centros.
5. Refinar con Lloyd:
   - asignar cada punto al centro mÃ¡s cercano
   - recalcular centroides como media
   - iterar `iters` o hasta convergencia

**Ejemplo Rust (estructura)**

```rust
pub fn kmeans_pp_train(vectors: &[Vec<f32>], k: usize, iters: usize) -> Vec<Vec<f32>> {
    // NOTA: para datos enormes, samplea (IVF_TRAINING_SAMPLE)
    // 1) init kmeans++
    // 2) iters Lloyd
    // 3) retorna centroides
    unimplemented!()
}
```

### 7.2 SelecciÃ³n de clusters (nprobe)

**Idea**

- score(centroid, query) para todos los centroides (k suele ser 1024..8192)
- tomar top `nprobe`
- buscar solo esos clusters

```rust
pub fn select_probes(centroids: &[Vec<f32>], query: &[f32], nprobe: usize) -> Vec<usize> {
    let mut scored: Vec<(usize, f32)> = centroids.iter()
        .enumerate()
        .map(|(i, c)| (i, dot_f32(c, query)))
        .collect();
    scored.sort_by(|a,b| b.1.partial_cmp(&a.1).unwrap());
    scored.into_iter().take(nprobe).map(|x| x.0).collect()
}
```

### 7.3 CuantizaciÃ³n Q8 (per-vector scale, simÃ©trica)

**DefiniciÃ³n**

- `scale = max(|x|) / 127`
- `q[i] = clamp(round(x[i]/scale), -127..127) as i8`

```rust
#[derive(Clone)]
pub struct Q8Vec {
    pub scale: f32,
    pub data: Vec<i8>,
}

pub fn quantize_q8_per_vector(v: &[f32]) -> Q8Vec {
    let mut max_abs = 0.0f32;
    for &x in v { max_abs = max_abs.max(x.abs()); }
    let scale = if max_abs == 0.0 { 1.0 } else { max_abs / 127.0 };

    let mut data = Vec::with_capacity(v.len());
    for &x in v {
        let q = (x / scale).round().clamp(-127.0, 127.0) as i8;
        data.push(q);
    }
    Q8Vec { scale, data }
}
```

### 7.4 Dot Q8 escalado

- `raw = dot_i8(a.data, b.data)` en i32
- `score = raw as f32 * (a.scale * b.scale)`

```rust
pub fn dot_q8_scaled(a: &Q8Vec, b: &Q8Vec) -> f32 {
    let raw = dot_i8(&a.data, &b.data) as f32;
    raw * (a.scale * b.scale)
}
```

### 7.5 AVX2 dot(i8,i8) con fallback (ejemplo base)

```rust
#[inline]
pub fn dot_i8_fallback(a: &[i8], b: &[i8]) -> i32 {
    let mut acc: i32 = 0;
    for i in 0..a.len() {
        acc += (a[i] as i32) * (b[i] as i32);
    }
    acc
}

#[cfg(any(target_arch="x86", target_arch="x86_64"))]
#[inline]
pub fn dot_i8(a: &[i8], b: &[i8]) -> i32 {
    if std::is_x86_feature_detected!("avx2") {
        unsafe { dot_i8_avx2(a, b) }
    } else {
        dot_i8_fallback(a, b)
    }
}

#[cfg(any(target_arch="x86", target_arch="x86_64"))]
#[target_feature(enable = "avx2")]
unsafe fn dot_i8_avx2(a: &[i8], b: &[i8]) -> i32 {
    use std::arch::x86_64::*;
    debug_assert_eq!(a.len(), b.len());

    let mut sum = _mm256_setzero_si256();
    let mut i = 0usize;

    while i + 32 <= a.len() {
        let va = _mm256_loadu_si256(a.as_ptr().add(i) as *const __m256i);
        let vb = _mm256_loadu_si256(b.as_ptr().add(i) as *const __m256i);

        let va_lo = _mm256_cvtepi8_epi16(_mm256_castsi256_si128(va));
        let vb_lo = _mm256_cvtepi8_epi16(_mm256_castsi256_si128(vb));
        let va_hi = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(va, 1));
        let vb_hi = _mm256_cvtepi8_epi16(_mm256_extracti128_si256(vb, 1));

        let prod_lo = _mm256_mullo_epi16(va_lo, vb_lo);
        let prod_hi = _mm256_mullo_epi16(va_hi, vb_hi);

        let ones = _mm256_set1_epi16(1);
        let acc_lo = _mm256_madd_epi16(prod_lo, ones);
        let acc_hi = _mm256_madd_epi16(prod_hi, ones);

        sum = _mm256_add_epi32(sum, acc_lo);
        sum = _mm256_add_epi32(sum, acc_hi);

        i += 32;
    }

    let mut tmp = [0i32; 8];
    _mm256_storeu_si256(tmp.as_mut_ptr() as *mut __m256i, sum);
    let mut acc = tmp.iter().sum::<i32>();

    while i < a.len() {
        acc += (a[i] as i32) * (b[i] as i32);
        i += 1;
    }
    acc
}
```

### 7.6 Flat scan dentro del cluster (top-k)

- Escanear Q8 vectors del cluster y mantener heap top-k

```rust
use std::cmp::Ordering;
use std::collections::BinaryHeap;

#[derive(Debug)]
struct Hit { id: u32, score: f32 }
impl PartialEq for Hit { fn eq(&self, o: &Self) -> bool { self.score == o.score } }
impl Eq for Hit {}
impl PartialOrd for Hit {
    fn partial_cmp(&self, o: &Self) -> Option<Ordering> { o.score.partial_cmp(&self.score) } // min-heap via reverse
}
impl Ord for Hit {
    fn cmp(&self, o: &Self) -> Ordering { self.partial_cmp(o).unwrap_or(Ordering::Equal) }
}

pub fn flat_scan_topk(cluster: &[(u32, Q8Vec)], q: &Q8Vec, k: usize) -> Vec<(u32, f32)> {
    let mut heap = BinaryHeap::with_capacity(k + 1);
    for (id, v) in cluster {
        let s = dot_q8_scaled(v, q);
        heap.push(Hit { id: *id, score: s });
        if heap.len() > k { heap.pop(); }
    }
    let mut out = heap.into_sorted_vec();
    out.reverse();
    out.into_iter().map(|h| (h.id, h.score)).collect()
}
```

---

## 8) Persistencia robusta (runs segmentados + checksum + truncado seguro)

### Problema a resolver

El formato append-only actual con un archivo Ãºnico no escala para:

- compaction incremental,
- recovery rÃ¡pido,
- corrupciÃ³n en tail,
- merges parciales.

### Record format recomendado (simple y seguro)

**Header fijo** (little-endian):

- `MAGIC u32` (ej. 0x524B5631 = "RKV1")
- `VERSION u16`
- `FLAGS u16` (op, reserved)
- `LEN u32` (payload bytes)
- `CRC32 u32` (payload)
- `OFFSET u64` (monÃ³tono)
- `ID_LEN u16`
- `...` (payload)

Payload:

- `id bytes`
- `vector_q8 bytes` (dim)
- `scale f32`
- `meta bytes` (JSON o msgpack) + `meta_len u32`

**Truncado seguro**

- Al leer:
  - si no hay header completo â†’ fin (ok)
  - si LEN excede lÃ­mite â†’ fin (ok)
  - si CRC falla â†’ truncar desde el Ãºltimo offset vÃ¡lido (o parar y marcar corrupto, segÃºn polÃ­tica)
  - nunca â€œpanicâ€ por tail parcial

### CompactaciÃ³n incremental (LSM-like)

- Cada cluster mantiene runs (archivos) append-only.
- Cuando:
  - tombstones/updates superan ratio,
  - o runs superan N,
  - o bytes exceden umbral,
    entonces:
  - elegir subset de runs antiguos,
  - merge en un nuevo run compacto (solo Ãºltima versiÃ³n por id),
  - swap atÃ³mico (rename),
  - actualizar manifest cluster.

**NUNCA** reescribir todo el dataset en un solo pass.

---

## 9) Concurrencia y uso de CPU (realista para 50M)

### Lecturas

- Query:
  - escoger probes (centroids)
  - paralelizar por cluster (rayon) cuando `nprobe` >= 8 y CPU lo permite
  - top-k global: merge por heaps/partial sorts

### Escrituras

- Upsert:
  - asignaciÃ³n cluster â†’ lock solo del cluster (no lock global)
  - append run â†’ flush segÃºn polÃ­tica (fsync configurable)
  - actualizar Ã­ndices in-memory (si existen) sin bloquear lecturas excesivamente

### Locks recomendados

- Evitar un `RwLock<HashMap<collection,...>>` gigante para el hot path.
- Preferir:
  - lock por colecciÃ³n,
  - lock por cluster,
  - o sharded locks (ej. 64 shards por hash(id)).

---

## 10) Seguridad (mÃ­nimo maduro)

Si `RUSTKISS_API_KEY` o `API_KEY` estÃ¡ configurado:

- Exigir `Authorization: Bearer <token>` en **todas** las rutas (incluye SSE).
- Rechazar si falta header o token incorrecto.
- Nunca loguear API keys ni headers sensibles.

Modo local:

- `bind=127.0.0.1` puede permitir open routes (opcional), pero debe ser explÃ­cito en config.
  Modo protegido:
- `--bind 0.0.0.0` o `--unsafe-bind` obliga a usar proxy o API key.

---

## 11) Benchmarks y tests (no opcional)

### Tests obligatorios

1. `persist_roundtrip_q8`:
   - insertar N, cerrar, abrir, buscar, verificar IDs/metas.

2. `tail_truncation_safe`:
   - simular archivo truncado en medio de record, verificar que open no corrompe ni peta.

3. `checksum_detection`:
   - corromper bytes y verificar detecciÃ³n.

4. `avx2_vs_scalar_exact`:
   - si hay AVX2, comparar i32 exacto.

5. `dims_matrix`:
   - dims: 384..8192, dataset pequeÃ±o, todo pasa.

### Bench mÃ­nimo (reproducible)

- dims: 768 y 4096 (mÃ­nimo)
- N: 100k, 1M (si posible)
- mÃ©tricas:
  - latencia p50/p95/p99
  - QPS
  - RAM aproximada
  - disco (tamaÃ±o runs)

- comparar:
  - f32 scan (baseline)
  - Q8 scan
  - IVF nprobe 8/16/32

---

## 12) Checklist de â€œlisto para DiskANN/Vamanaâ€

NO avances a DiskANN si no se cumple:

- Persistencia por runs estable con checksum y truncado seguro.
- Compaction incremental en background y sin corrupciÃ³n.
- IVF_FLAT_Q8 default estable (tests + bench).
- AVX2 + fallback verificados.
- ConfiguraciÃ³n/flags claros y documentados.
- Bench comparable y repetible.

Luego DiskANN:

- builder offline,
- grafo en disco,
- vectores comprimidos en RAM,
- cache/paging,
- updates (definir si batch o incremental).

---

## 13) Tu tarea inmediata (orden estricto)

1. Implementar y dejar default `INDEX_KIND=IVF_FLAT_Q8`.
2. AÃ±adir kmeans++ + persistencia de centroides.
3. AÃ±adir Q8 persistente por cluster + flat scan top-k.
4. Paralelizar probes + SIMD donde aplique.
5. Migrar persistencia a runs segmentados con checksum + truncado seguro.
6. CompactaciÃ³n incremental por clusters/runs (no full rewrite).
7. AVX2 int8 dot + tests de equivalencia exacta.
8. Hardening (crash/tail/corruption).
9. Solo despuÃ©s: plan e implementaciÃ³n DiskANN/Vamana.

No improvises: cada paso es un PR pequeÃ±o con tests y bench.
Git: Tienes permitido utilizar comandos git para versionar tu trabajo.

---

## 14) Fase actual: PreparaciÃ³n DiskANN/Vamana

1. **Interfaces claras**
   - `VectorIndex` para los Â¡ndices en RAM (HNSW, IVF/Q8).
   - `DiskVectorIndex` cubre la inicializaciÂ¢n/sync genâ€šrica en disco.
   - `DiskAnnIndex` extiende lo anterior con operaciones especÂ¡ficas (construir/cargar/borrar el grafo, exponer progreso/parÂ metros).
2. **Manifest dedicado**
   - AÂ¤adir a `manifest.json` un bloque estable con metadatos de grafo (versiÂ¢n, rutas, timestamp, parÂ metros del builder).
   - Los tests de roundtrip deben verificar que esos campos sobreviven restart incluso cuando no hay grafo.
3. **MÂ¢dulo `vector/diskann`**
   - Crear carpeta con archivos pequeÂ¤os (`mod.rs`, `builder.rs`, `graph.rs`, `io.rs`, `scheduler.rs`) en lugar de inflar `vector/mod.rs`.
   - Promover utilidades comunes (I/O atÂ¢mico, checksums, lecturas chunked) a `src/utils/` cuando se repitan.
4. **Bench sin castigar SSD**
   - `bench.rs` debe permitir generar el dataset completo una sola vez por dim y reutilizarlo para baseline/IVF/DiskANN.
   - Solo borrar el directorio al final (salvo `--keep-data`); registrar timestamps de inicio/fin ya implementados.
5. **DocumentaciÂ¢n**
   - Actualizar `docs/BENCHMARKS.md` y README con nuevos flags/modos.
   - Guardar outputs textuales con `nprobe`, `centroid_count`, `q8_refine_topk`, etc.

La fase se considera cerrada cuando:
- El trait `DiskAnnIndex` exista y tenga un esqueleto funcional.
- El manifest soporte metadatos de Â¡ndice en disco sin romper colecciones viejas.
- `bench` pueda ejecutar baseline/IVF/DiskANN reutilizando datasets.
- Haya docs/tests que expliquen cÂ¢mo habilitar validar DiskANN.

---

## 15) Active Order: Luma â€” Configuration & Limits Unification

### ğŸ¯ Objetivo

Unificar **todos los lÃ­mites operativos y anti-DoS** de Luma para que:

1. **Puedan configurarse por lÃ­nea de comandos**
2. **Acepten unidades humanas (MB, no bytes)**
3. **Tengan fallback por variables de entorno**
4. **Mantengan defaults seguros**
5. **No existan valores hardcodeados dispersos**

Prioridad estricta:

```
CLI args > Environment variables > Default values
```

---

## ğŸ§  Principios de diseÃ±o (NO negociables)

* âŒ No se aceptan bytes en CLI (`1048576`)
* âœ… Solo MB (`--max-body-mb 20`)
* âŒ No duplicar parsing (un solo resolver por lÃ­mite)
* âœ… Todo lÃ­mite debe:
  * estar documentado
  * tener default
  * ser trazable en logs al boot
* âŒ No introducir perfiles mÃ¡gicos todavÃ­a (`prod/ingest`)
* âœ… Arquitectura explÃ­cita, no implÃ­cita

---

## ğŸ“Œ LÃ­mites soportados (estado objetivo)

| LÃ­mite                 | CLI Flag                 | ENV                      | Default          |
| ---------------------- | ------------------------ | ------------------------ | ---------------- |
| Max body size          | `--max-body-mb`          | `MAX_BODY_MB`            | `1`              |
| Max JSON size          | `--max-json-mb`          | `MAX_JSON_MB`            | `0.0625` (64 KB) |
| Max vector dim         | `--max-vector-dim`       | `MAX_VECTOR_DIM`         | `4096`           |
| Max top-k              | `--max-k`                | `MAX_K`                  | `256`            |
| Max key length         | `--max-key-len`          | `MAX_KEY_LEN`            | `512`            |
| Max collection len     | `--max-collection-len`   | `MAX_COLLECTION_LEN`     | `64`             |
| WAL retention segments | `--wal-retention`        | `WAL_RETENTION_SEGMENTS` | `8`              |
| Request timeout        | `--request-timeout-secs` | `REQUEST_TIMEOUT_SECS`   | `30`             |

---

## ğŸ› ï¸ Orden de implementaciÃ³n (obligatorio)

### **Tarea 1 â€” Crear resolvers unificados**

Crear en `config/resolve.rs` funciones **puras** por lÃ­mite.

### **Tarea 2 â€” Eliminar lectura directa de ENV**

âŒ Prohibido: `std::env::var("MAX_BODY_BYTES")`
âœ… Ãšnico punto vÃ¡lido: `let max_body_bytes = resolve_max_body_mb();`

### **Tarea 3 â€” Actualizar `Config::from_env`**

`Config` **ya no lee ENV directamente**. Solo recibe valores ya resueltos.

### **Tarea 4 â€” Alinear middleware Axum**

Confirmar que **solo** usa config.

### **Tarea 5 â€” Normalizar naming**

Eliminar `MAX_BODY_BYTES`, reemplazar por `MAX_BODY_MB`.

### **Tarea 6 â€” Logging obligatorio al boot**

Al iniciar Luma:

```text
[config] max_body_mb = 20
[config] max_json_mb = 0.0625
...
```

### **Tarea 7 â€” DocumentaciÃ³n CLI**

Ejemplo vÃ¡lido:

```bash
luma serve \
  --port 8080 \
  --max-body-mb 20 \
  --max-json-mb 1 \
  --max-k 128 \
  --request-timeout-secs 60
```

---

## ğŸš¨ Reglas Anti-DoS (criterio de seguridad)

* `max_body_mb` **lÃ­mite duro HTTP**
* `max_json_mb` **lÃ­mite semÃ¡ntico**
* `max_vector_dim`, `max_k`, `max_key_len` â†’ validar **antes** de ejecutar lÃ³gica
* Errores deben devolver:
  * `413 Payload Too Large`
  * `422 Unprocessable Entity`

---

## ğŸ“˜ Objetivo de esta secciÃ³n (DocumentaciÃ³n y SemÃ¡ntica)

Explicar **quÃ© protege cada lÃ­mite**, **en quÃ© capa actÃºa**, y **por quÃ© existen varios lÃ­mites distintos**.

### ğŸ§  Modelo mental correcto

Luma aplica **defensa en profundidad**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP Request (raw bytes) â”‚  â† MAX_BODY_MB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON parsing / decoding  â”‚  â† MAX_JSON_MB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Semantic validation      â”‚  â† vector dim, k, key lenâ€¦
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ” Diferencia crÃ­tica: `MAX_BODY_MB` vs `MAX_JSON_MB`

#### ğŸ”¹ `MAX_BODY_MB` â€” LÃ­mite fÃ­sico (transporte)
**Protege contra**: Requests gigantes, uploads accidentales.
**ActÃºa**: Middleware HTTP (`DefaultBodyLimit`).

#### ğŸ”¹ `MAX_JSON_MB` â€” LÃ­mite lÃ³gico (contenido)
**Protege contra**: JSONs inflados, ataques de parsing.
**ActÃºa**: DespuÃ©s de parsear HTTP.

### ğŸ§  RelaciÃ³n correcta entre ambos

Regla **no escrita pero obligatoria**:

```
MAX_JSON_MB <= MAX_BODY_MB
```

---

## ğŸ§© Tabla resumida (para README)

| LÃ­mite                 | Capa      | Protege         | Error tÃ­pico             |
| ---------------------- | --------- | --------------- | ------------------------ |
| `MAX_BODY_MB`          | HTTP      | Infraestructura | `413 Payload Too Large`  |
| `MAX_JSON_MB`          | Parsing   | CPU / Memoria   | `413 Payload Too Large`  |
| `MAX_VECTOR_DIM`       | SemÃ¡ntica | Algoritmo       | `422 Invalid vector dim` |
| `MAX_K`                | SemÃ¡ntica | Performance     | `422 Invalid k`          |
| `REQUEST_TIMEOUT_SECS` | EjecuciÃ³n | Latencia        | `408 / 504`              |

---

## ğŸ§ª ObligaciÃ³n de validaciÃ³n

Al boot, Luma debe **rechazar configuraciÃ³n invÃ¡lida**:

```text
ERROR: MAX_JSON_MB (2) cannot be greater than MAX_BODY_MB (1)
```